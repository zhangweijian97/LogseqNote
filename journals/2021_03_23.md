---
title: Mar 23rd, 2021
---

## TODO
### 毕设 读论文
#### [[CoLAKE Sun 2020]] #[[KG Knowledge Graph 知识图谱]] #KEPLM
##### CoLAKE: Contextualized Language and Knowledge Embedding
##### abstract
###### learns contextualized representation for both language and knowledge
###### extended MLM objective
##### introduction
###### 提到 [[ERNIE]] 和 #[[KnowBert Peters 2019]]，三个缺点
####### separately pre-trained embeddings
####### only entity embeddings
####### static and need re-train
###### 简述CoLAKE
####### 和之前模型对比，能够动态表示
####### WK graph
###### 实验，GLUE
###### 贡献
##### related work
###### 语言表示，略
###### 知识表示，略
###### 混合表示
####### [[KEPLER Wang 2019]]
####### K-BERT
####### BERT-MK
##### 模型
###### WK graph
####### 句子
####### tokenize
####### sequence of tokens
####### fully connect
####### word graph
####### 找到实体并替换，叫anchor nodes
####### 每个anchor node 随机选15个neighboring relations and entities
###### 架构
####### embedding layer
######## token embedding，3 lookup table for，分别，最后concatenate
######### words，跟随了RoBERTa的BPE
######### entities，learn as common knowledge embedding methods
######### relations
######## type embedding
######### node type，word，entity，relation
######## position embedding
######### soft-position index Liu 2020
####### Masked Transformer Encoder
####### Pre-Training Objective
######## 和MLM类似
######## 输入有3种node
######## 学到不同的东西
###### 训练
####### Mixed CPU-GPU Training
####### Negative Sampling
### MLP 继续写 report
### 补一觉
## inbox
### 毕设会议信息
#### [[MSc Project]]
#### Meeting ID: 864 3171 1138
:PROPERTIES:
:later: 1616512339168
:END:
#### Passcode: 5mu2dUYD
#### https://ed-ac-uk.zoom.us/j/86431711138
