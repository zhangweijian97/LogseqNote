---
title: Mar 23rd, 2021
---

## TODO
### 毕设 读论文
#### [[CoLAKE Sun 2020]] #[[KG Knowledge Graph 知识图谱]] #KEPLM
##### CoLAKE: Contextualized Language and Knowledge Embedding
##### abstract
###### learns contextualized representation for both language and knowledge
###### extended MLM objective
##### introduction
###### 提到 [[ERNIE]] 和 #[[KnowBert Peters 2019]]，三个缺点
####### separately pre-trained embeddings
####### only entity embeddings
####### static and need re-train
###### 简述CoLAKE
####### 和之前模型对比，能够动态表示
####### WK graph
###### 实验，GLUE
###### 贡献
##### related work
###### 语言表示，略
###### 知识表示，略
###### 混合表示
####### [[KEPLER Wang 2019]]
####### K-BERT
####### BERT-MK
##### 模型
###### WK graph
####### 句子
####### tokenize
####### sequence of tokens
####### fully connect
####### word graph
####### 找到实体并替换，叫anchor nodes
####### 每个anchor node 随机选15个neighboring relations and entities
###### 架构
###### embedding layer
####### token embedding，3 lookup table for，分别
######## words，跟随了RoBERTa的BPE
######## entities，learn as common knowledge embedding methods
######## relations
####### type embedding
####### position embedding
### MLP 继续写 report
### 补一觉
