---
title: NLU Lecture Notes
---

### [[NLU Lecture 1-16]]
### [[NLU Lecture 1 Introduction]]
### [[NLU Lecture 2 Machine Translation]]
### [[NLU Lecture 3 Machine translation with n-grams]]
### [[NLU Lecture 4 Perceptrons]]
### [[NLU Lecture 5 n-gram language modelling with feedforward neural networks]]
### [[NLU Lecture 6 Recurrent Neural Networks and LSTMs]]
### [[NLU Lecture 7 Sequence-to-sequence models with attention]]
### [[NLU Lecture 8 Evaluating Machine Translation Systems]]
### [[NLU Lecture 9 Open-Vocabulary Models]]
### [[NLU Lecture 10 Transformer]]
### [[NLU Lecture 11 Word Embeddings]]
### [[NLU Lecture 12 Contextualised Word Embeddings]]
### [[NLU Lecture 14 Word Embeddings are Biased]]
### [[NLU Lecture 15 The Environmental and Human Cost of NLP]]
### [[NLU Lecture 16 Neural Parsing]]
### [[NLU Lecture 17 Recurrent Neural Network Grammars]]
### [[NLU Lecture 18 Unsupervised Parsing]]
### NLU Lecture 19 Semantic Parsing
### NLU Lecture 20 Paraphrasing
### NLU Lecture 21 Applications of Paraphrasing
### NLU Lecture 22 Summarization 1
### NLU Lecture 23 Summarization 2
### NLU Lecture 24 Data-to-text Generation
### NLU Lecture 25
### NLU Lecture
